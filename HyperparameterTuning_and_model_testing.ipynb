{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import deepchem as dc\n",
    "from deepchem.models import GCNModel\n",
    "from deepchem.feat.graph_data import GraphData\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolops, Draw\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader, ImbalancedSampler\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "import dgl\n",
    "import dgllife\n",
    "from dgllife.model import GCN\n",
    "from dgllife.model import GAT\n",
    "from dgllife.model.readout import WeightedSumAndMax\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# see torch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# run inputs\n",
    "model_type = input(\"Enter the model type GCN, GNN, GAT: \")\n",
    "if model_type not in [\"GCN\", \"GNN\", \"GAT\"]:\n",
    "    raise ValueError(\"Model type not supported\")\n",
    "\n",
    "motif_used = input(\"Enter if motif is used, TRUE or FALSE: \").strip().upper() == \"TRUE\"\n",
    "test_used = input(\"Enter if test is used, TRUE or FALSE: \").strip().upper() == \"TRUE\"\n",
    "print(\"Model type: \", model_type)\n",
    "print(\"Motif used: \", motif_used)\n",
    "print(\"Test used: \", test_used)\n",
    "\n",
    "# failure detection\n",
    "assert type(model_type) == str\n",
    "assert type(motif_used) == bool\n",
    "assert type(test_used) == bool\n",
    "print(\"Model type: \", type(model_type))\n",
    "print(\"Motif used: \", type(motif_used))\n",
    "print(\"Test used: \", type(test_used))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = r\"FÃ¦rdig_data_med_clin_data.csv\"\n",
    "molecules = pd.read_csv(path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create molecule graph for each molecule.\n",
    "featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "molecules[\"atom_graph\"] = [featurizer.featurize(smiles)[0] for smiles in molecules[\"SMILES\"]]\n",
    "\n",
    "# remove molecules that could not be converted to graphs\n",
    "molecules = molecules[molecules[\"atom_graph\"].apply(lambda x: isinstance(x, GraphData))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store the molecule graphs\n",
    "molecules_graph_data = pd.DataFrame()\n",
    "\n",
    "molecules_graph_data[\"atom_graph\"] = molecules[\"atom_graph\"]\n",
    "molecules[\"atom_graph\"] = molecules.index\n",
    "\n",
    "\n",
    "#placeholder graph for motifs(not used)\n",
    "smiles = \"C(c1ccc(cc1)N)(=O)OCC\"\n",
    "motif_atom_graph_placeholder = featurizer.featurize([(smiles)])[0]\n",
    "\n",
    "motif_atom = pd.DataFrame({\"atom_graph\": [motif_atom_graph_placeholder]})\n",
    "\n",
    "motif_atom_index = 50000\n",
    "\n",
    "#set index to 50000 to avoid overlap with the molecules\n",
    "motif_atom.index = (motif_atom_index,)\n",
    "\n",
    "# add the motif to the dataframe of graphs\n",
    "molecules_graph_data = pd.concat([molecules_graph_data, motif_atom])\n",
    "\n",
    "# convert to dgl graph which are used in the model later\n",
    "dgl_g = [dgl.add_self_loop(graph.to_dgl_graph()) for graph in molecules_graph_data[\"atom_graph\"]]\n",
    "molecules_graph_data[\"dgl_graph\"] = dgl_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## gets the motifs from the molecules\n",
    "def get_motifs(mol, motif_dict, ignore_dict=False):\n",
    "    motifs = motif_dict\n",
    "\n",
    "    sssr = rdmolops.GetSymmSSSR(mol)\n",
    "    for ring in sssr:\n",
    "        atom_symbols = tuple(sorted(mol.GetAtomWithIdx(idx).GetSymbol() for idx in ring))\n",
    "        bond_types = set()\n",
    "        for i in range(len(ring)):\n",
    "            bond = mol.GetBondBetweenAtoms(ring[i], ring[(i+1) % len(ring)])\n",
    "            bond_types.add(str(bond.GetBondType()))\n",
    "        bond_type = \"AROMATIC\" if \"AROMATIC\" in bond_types else \"MIXED\" if len(bond_types) > 1 else bond_types.pop()\n",
    "        motif_= str((atom_symbols, bond_type))\n",
    "\n",
    "        if ignore_dict != True:\n",
    "            if motif_ not in motifs.keys():\n",
    "                print(\"value not added\")\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                print(\"value addedd\")\n",
    "                motifs[motif_] += 1\n",
    "        else:\n",
    "            motifs[motif_] = 1\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Add bonds to the motifs\n",
    "    for bond in mol.GetBonds():\n",
    "        if not bond.IsInRing():\n",
    "            start_atom_symbol = mol.GetAtomWithIdx(bond.GetBeginAtomIdx()).GetSymbol()\n",
    "            end_atom_symbol = mol.GetAtomWithIdx(bond.GetEndAtomIdx()).GetSymbol()\n",
    "            bond_type = str(bond.GetBondType())\n",
    "            atom_symbols = tuple(sorted([start_atom_symbol, end_atom_symbol]))\n",
    "            motif_ = str((atom_symbols, bond_type))\n",
    "            if ignore_dict != True:\n",
    "                if motif_ not in motifs:\n",
    "                    continue\n",
    "                else:\n",
    "                    motifs[motif_] += 1\n",
    "            else:\n",
    "                motifs[motif_] = 1\n",
    "        \n",
    "    return motifs\n",
    "\n",
    "## process motifs for a single molecule\n",
    "def process_single_molecule(smiles, motif_dict, ignore_dict=False):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        print(f\"Failed to process molecule with SMILES: {smiles}\")\n",
    "        return {}\n",
    "    \n",
    "    motifs_dict = get_motifs(molecule, motif_dict, ignore_dict)\n",
    "    return motifs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motif count across all molecules\n",
    "motif_count_dict = {}\n",
    "\n",
    "for idx, molecule in molecules.iterrows():\n",
    "    single_dict = process_single_molecule(molecule[\"SMILES\"], {}, ignore_dict=True)\n",
    "    \n",
    "    for key, value in single_dict.items():\n",
    "        if key not in motif_count_dict:\n",
    "            motif_count_dict[key] = 1\n",
    "        else:\n",
    "            motif_count_dict[key] += 1\n",
    "\n",
    "# filter motifs with count less than 5\n",
    "motif_count_dict_with_more_than_5 = {}\n",
    "\n",
    "for key, value in motif_count_dict.items():\n",
    "    if value > 5:\n",
    "        motif_count_dict_with_more_than_5[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#one-hot encode the motifs from motif.columns\n",
    "motif_bag = pd.get_dummies(motif_count_dict_with_more_than_5.keys(), dtype=float)\n",
    "\n",
    "# create dict with motif as keys and 0 as values\n",
    "motif_dict = dict.fromkeys(motif_count_dict_with_more_than_5.keys(), 0)\n",
    "\n",
    "# sort the dict keys for consistency when using the dict across all molecules again\n",
    "motif_dict = dict(sorted(motif_dict.items()))\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# add motif nodes to the motif graph\n",
    "for idx, row in motif_bag.iterrows():\n",
    "    # Convert the row to a dictionary of features\n",
    "    features = row.to_dict()\n",
    "    # Add the node to the graph with its features\n",
    "    # find which column is 1 and set the name of the node to that column name\n",
    "    for key, value in features.items():\n",
    "        if value == 1.0:\n",
    "            G.add_node(key, **features)\n",
    "            # tf_weight = motif_count_dict_with_more_than_5[key]\n",
    "            # extraft the value of the first row in the motif dataframe, in the column that is column_name\n",
    "            # G.nodes[key]['tf_weight'] = tf_weight\n",
    "            G.nodes[key][\"atom_graph\"] = motif_atom_index\n",
    "            G.nodes[key]['node_type'] = 'motif'\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, molecule in molecules.iterrows():\n",
    "    motif = process_single_molecule(molecule['SMILES'],motif_dict.copy())\n",
    "    if motif == {}:\n",
    "        continue\n",
    "    # add the motif for the molecule to the graph as a node \n",
    "    # add the motif dictionary to the graph\n",
    "    G.add_node(molecule[\"SMILES\"], **motif)\n",
    "    G.nodes[molecule[\"SMILES\"]]['atom_graph'] = molecule[\"atom_graph\"]\n",
    "    G.nodes[molecule[\"SMILES\"]]['node_type'] = 'molecule'\n",
    "    G.nodes[molecule[\"SMILES\"]]['Approval'] = molecule[\"Vores_approval\"]\n",
    "\n",
    "\n",
    "\n",
    "def tf_idf(molecule,motif, molecules_count):\n",
    "    term_frequency_all_mol = motif_count_dict_with_more_than_5[motif]\n",
    "    # [:-3] is to ignore the last entries which is the non-motif features\n",
    "    print(G.nodes[molecule].values())\n",
    "    tf = G.nodes[molecule][motif]/sum(list(G.nodes[molecule].values())[:-3])\n",
    "    idf = np.log(molecules_count / term_frequency_all_mol)\n",
    "    print(G.nodes[molecule][motif])\n",
    "    print(f\"TF: {tf}\")\n",
    "    print(f\"IDF: {idf}\")\n",
    "\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each molecule, add an edge between the molecule and the motif if the motif is present in the molecule(ie. the value of the motif in the molecule is greater than 0)\n",
    "for molecule in G.nodes():\n",
    "    if G.nodes[molecule]['node_type'] == 'molecule':\n",
    "        print(f\"Processing molecule {molecule}\")\n",
    "        for motif in G.nodes():\n",
    "            if G.nodes[motif]['node_type'] == 'motif':\n",
    "                print(f\"Processing motif {motif}\")\n",
    "                print(\"get_value: \", G.nodes[molecule].get(motif, 0))\n",
    "                if G.nodes[molecule].get(motif, 0) > 0:\n",
    "                    print(\"here\")\n",
    "                    G.add_edge(motif, molecule , weight=tf_idf(molecule, motif, len(molecules)))\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a co-occurence matrix for the pmi values\n",
    "cooccurence_matrix = pd.DataFrame(index=motif_bag.columns, columns=motif_bag.columns, dtype=int)\n",
    "\n",
    "cooccurence_matrix = cooccurence_matrix.fillna(0)\n",
    "\n",
    "molecules = [node for node in G.nodes() if G.nodes[node]['node_type'] == 'molecule']\n",
    "motifs = [node for node in G.nodes() if G.nodes[node]['node_type'] == 'motif']\n",
    "\n",
    "# Iterate over molecules\n",
    "for molecule in molecules:\n",
    "    connected_motifs = [motif for motif in motifs if G.has_edge(motif, molecule)]\n",
    "    for i, motif in enumerate(connected_motifs):\n",
    "        for motif_2 in connected_motifs[i+1:]:\n",
    "            cooccurence_matrix.loc[motif, motif_2] += 1\n",
    "            cooccurence_matrix.loc[motif_2, motif] += 1 \n",
    "\n",
    "# values here the raw count of each motif\n",
    "for i, count in motif_count_dict_with_more_than_5.items():\n",
    "    cooccurence_matrix.loc[i,i] = count\n",
    "\n",
    "# divide each entry in the matrix with number of molecules\n",
    "cooccurence_matrix = cooccurence_matrix.div(len(molecules))\n",
    "\n",
    "# pmi value function\n",
    "def pmi_value(motif_1, motif_2, cooccurence_matrix):\n",
    "    pmi = np.log(cooccurence_matrix.loc[motif_1, motif_2] / (cooccurence_matrix.loc[motif_1, motif_1] * cooccurence_matrix.loc[motif_2, motif_2]))\n",
    "    return pmi\n",
    "\n",
    "\n",
    "# add edges between motifs and add the pmi value as the weight, if the pmi value is 0, the edge is not added\n",
    "for i, motif in enumerate(motifs):\n",
    "    for motif_2 in motifs[i+1:]:\n",
    "        if pmi_value(motif, motif_2, cooccurence_matrix) <= 0:\n",
    "            continue\n",
    "        G.add_edge(motif, motif_2, weight=max(pmi_value(motif, motif_2, cooccurence_matrix), 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to a approval value for the motifs for the model to work(not used)\n",
    "for i in G.nodes:\n",
    "    if G.nodes[i][\"node_type\"] == \"motif\":\n",
    "        G.nodes[i][\"Approval\"] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features to tensors and store them as x and y in the graph\n",
    "for i, attr_ in G.nodes(data=True):\n",
    "    attr = list(attr_.values())\n",
    "    if attr_[\"node_type\"] == \"molecule\":\n",
    "        G.nodes[i][\"x\"] = torch.tensor(attr[:-3])\n",
    "        G.nodes[i][\"y\"] = torch.tensor(attr[-1])\n",
    "    else:\n",
    "        G.nodes[i][\"x\"] = torch.tensor(attr[:-3])\n",
    "        G.nodes[i][\"y\"] = torch.tensor(attr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Data object for training \n",
    "node_features = []\n",
    "node_labels = []\n",
    "edge_index = [[],[]]\n",
    "mask = []\n",
    "atom_graphs = []\n",
    "\n",
    "\n",
    "for i, attr in G.nodes(data=True):\n",
    "    \n",
    "    node_features.append(attr[\"x\"])\n",
    "    node_labels.append(attr[\"y\"])\n",
    "    if attr[\"node_type\"] == \"molecule\":\n",
    "        mask.append(True)\n",
    "        atom_graphs.append(attr[\"atom_graph\"])\n",
    "        \n",
    "    else: \n",
    "        mask.append(False)\n",
    "        atom_graphs.append(attr[\"atom_graph\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "motif_indexes = {name: i for i, name in enumerate(G.nodes)}\n",
    "\n",
    "\n",
    "\n",
    "for edge in G.edges:\n",
    "    edge_index[0].append(motif_indexes[edge[0]])\n",
    "    edge_index[1].append(motif_indexes[edge[1]])\n",
    "\n",
    "\n",
    "edge_weights = [G[u][v][\"weight\"] for u, v in G.edges()]\n",
    "\n",
    "node_features = torch.stack(node_features)\n",
    "node_labels = torch.tensor(node_labels)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "mask = torch.tensor(mask, dtype=torch.bool)\n",
    "atom_graphs = torch.tensor(atom_graphs, dtype=torch.long)\n",
    "\n",
    "\n",
    "data = Data(x=node_features,edge_index=edge_index,y=node_labels, edge_weight=edge_weights, atom_graphs=atom_graphs)\n",
    "\n",
    "split_sizes = (0.7,0.2,0.1)\n",
    "\n",
    "# only use molecules for training, validation and testing, motifs are not used except for the motif graph\n",
    "molecule_nodes = torch.nonzero(mask, as_tuple=False).view(-1)\n",
    "num_mol_nodes = molecule_nodes.size(0)\n",
    "\n",
    "train_size = int(split_sizes[0]*num_mol_nodes)\n",
    "val_size = int(split_sizes[1]*num_mol_nodes)\n",
    "test_size = int(split_sizes[2]*num_mol_nodes)\n",
    "\n",
    "shuffled_mol_indices = molecule_nodes[torch.randperm(num_mol_nodes)]\n",
    "train_idx = shuffled_mol_indices[:train_size]\n",
    "val_idx = shuffled_mol_indices[train_size: train_size+val_size]\n",
    "test_idx = shuffled_mol_indices[train_size+val_size:]\n",
    "\n",
    "\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "\n",
    "data.train_mask[train_idx] = True\n",
    "data.val_mask[val_idx] = True\n",
    "data.test_mask[test_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, gnn_norm, activation, dropout):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "\n",
    "        if gnn_norm == \"Both\":\n",
    "            gnn_norm = True\n",
    "        if gnn_norm == \"None\":\n",
    "            gnn_norm = False\n",
    "\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.res_feats = []\n",
    "        self.convs = []   \n",
    "\n",
    "        input_dim = in_feats\n",
    "        \n",
    "\n",
    "        for i, hidden_dim in enumerate(hidden_feats):\n",
    "            if i == len(hidden_feats) - 1:\n",
    "                continue\n",
    "            self.convs.append(GCNConv(input_dim, hidden_dim, normalize = gnn_norm))\n",
    "            input_dim = hidden_dim\n",
    "        self.convs.append(GCNConv(input_dim, hidden_feats[-1], normalize = gnn_norm))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "\n",
    "        for i, conv in enumerate(self.convs[:-1]):  \n",
    "            x = conv(x, edge_index, edge_weight=edge_weight)\n",
    "            if self.dropout:\n",
    "                x = self.dropout[i](x)\n",
    "            x = self.activation[i](x)\n",
    "        x = self.convs[-1](x, edge_index, edge_weight=edge_weight)  \n",
    "        x = self.activation[-1](x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleGAT(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, heads, activation,agg_modes, dropout):\n",
    "        super(SimpleGAT, self).__init__()\n",
    "\n",
    "\n",
    "        if agg_modes[0] == 'flatten':\n",
    "            agg_modes = [True]*len(hidden_feats)\n",
    "        elif agg_modes[0] == 'mean':\n",
    "            agg_modes = [False]*len(hidden_feats)\n",
    "\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.convs = []\n",
    "        \n",
    "        input_dim = in_feats\n",
    "\n",
    "        for i, hidden_dim in enumerate(hidden_feats):\n",
    "            if i == len(hidden_feats) - 1:\n",
    "                continue\n",
    "            self.convs.append(GATConv(input_dim, hidden_dim, heads=heads[i], concat=agg_modes[i], dropout=dropout[i]))\n",
    "            if agg_modes[0]:\n",
    "                input_dim = hidden_dim*heads[i]\n",
    "            else:\n",
    "                input_dim = hidden_dim\n",
    "            \n",
    "        self.convs.append(GATConv(input_dim, hidden_feats[-1], heads=heads[-1], concat=agg_modes[-1], dropout=dropout[-1]))\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation[i](x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.activation[-1](x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to batch the dgl graphs during training\n",
    "def indexes_to_batch_dgl_graphs(indexes, batch):\n",
    "    indexes = batch.atom_graphs.tolist()\n",
    "\n",
    "    atom_graphs = [molecules_graph_data.loc[index, \"dgl_graph\"] for index in indexes]\n",
    "    \n",
    "    return dgl.batch(atom_graphs)\n",
    "\n",
    "# function to save the results of the trials to a json file during hyperparameter optimization\n",
    "def save_trial_results(stopped_early, folder_path, trial, best_val_loss, epoch_train_predict_values, epoch_train_targets_values, epoch_val_predict_values, epoch_val_targets_values, all_train_loss, all_val_loss, epochs, test_used=False, epoch_test_predict_values=None, epoch_test_targets_values=None, test_loss=None):\n",
    "    json_path = os.path.join(folder_path, f\"trial_{trial.number}.json\")\n",
    "    json_object = {\n",
    "        \"trail_number\": trial.number,\n",
    "        \"trial_params\": trial.params,\n",
    "        \"best_val_loss\": best_val_loss[0],\n",
    "        \"best_epoch\": best_val_loss[1],\n",
    "        \"epoch_train_predict_values\": epoch_train_predict_values,\n",
    "        \"epoch_train_targets_values\": epoch_train_targets_values,\n",
    "        \"epoch_val_predict_values\": epoch_val_predict_values,\n",
    "        \"epoch_val_targets_values\": epoch_val_targets_values,\n",
    "        \"all_train_loss\": all_train_loss,\n",
    "        \"all_val_loss\": all_val_loss,\n",
    "        \"stoped_early\": stopped_early,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "    if test_used:\n",
    "        json_object[\"test_predict_values\"] = epoch_test_predict_values\n",
    "        json_object[\"test_targets_values\"] = epoch_test_targets_values\n",
    "        json_object[\"test_loss\"] = test_loss\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(json_object, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Combined_model(torch.nn.Module):\n",
    "    def __init__(self, motif_param_dict, atom_param_dict, concat_size, MLPsize, include_motif):\n",
    "        super(Combined_model, self).__init__()\n",
    "        self.nfeat_name = \"x\"\n",
    "        self.include_motif = include_motif\n",
    "        in_feats_motif =  data.num_node_features\n",
    "        in_feats_atom = 30\n",
    "        \n",
    "\n",
    "        if model_type == \"GNN\":\n",
    "            if include_motif:\n",
    "                self.motif_model = SimpleGNN(in_feats=in_feats_motif,\n",
    "                                        hidden_feats=motif_param_dict[\"hidden_channels\"],\n",
    "                                        gnn_norm=motif_param_dict[\"gnn_norm\"],\n",
    "                                        activation=motif_param_dict[\"activation_function\"],\n",
    "                                        dropout=motif_param_dict[\"dropout\"],)\n",
    "                \n",
    "            self.atom_lvl_model = GCN(in_feats=in_feats_atom,\n",
    "                                hidden_feats=atom_param_dict[\"hidden_channels\"],\n",
    "                                gnn_norm=atom_param_dict[\"gnn_norm\"],\n",
    "                                activation=atom_param_dict[\"activation_function\"],\n",
    "                                dropout=atom_param_dict[\"dropout\"],\n",
    "                                allow_zero_in_degree=True)\n",
    "            \n",
    "        elif model_type == \"GCN\":\n",
    "            if include_motif:\n",
    "                self.motif_model = SimpleGNN(in_feats=in_feats_motif,\n",
    "                                        hidden_feats=motif_param_dict[\"hidden_channels\"],\n",
    "                                        gnn_norm=motif_param_dict[\"gnn_norm\"],\n",
    "                                        activation=motif_param_dict[\"activation_function\"],\n",
    "                                        dropout=motif_param_dict[\"dropout\"],)\n",
    "            \n",
    "            self.atom_lvl_model = GCN(in_feats=in_feats_atom,\n",
    "                                hidden_feats=atom_param_dict[\"hidden_channels\"],\n",
    "                                gnn_norm=atom_param_dict[\"gnn_norm\"],\n",
    "                                activation=atom_param_dict[\"activation_function\"],\n",
    "                                dropout=atom_param_dict[\"dropout\"],\n",
    "                                allow_zero_in_degree=True)\n",
    "            \n",
    "\n",
    "        elif model_type == \"GAT\":\n",
    "            if include_motif:\n",
    "                self.motif_model = SimpleGAT(in_feats=in_feats_motif,\n",
    "                                    hidden_feats=motif_param_dict[\"hidden_channels\"],\n",
    "                                    heads=motif_param_dict[\"heads\"],\n",
    "                                    activation=motif_param_dict[\"activation_function\"],\n",
    "                                    agg_modes = motif_param_dict[\"GAT_agg_modes\"],\n",
    "                                    dropout=motif_param_dict[\"dropout\"],)\n",
    "            \n",
    "            self.atom_lvl_model = GAT(in_feats=in_feats_atom,\n",
    "                                hidden_feats=atom_param_dict[\"hidden_channels\"],\n",
    "                                num_heads=atom_param_dict[\"heads\"],\n",
    "                                activations=atom_param_dict[\"activation_function\"],\n",
    "                                agg_modes = atom_param_dict[\"GAT_agg_modes\"],\n",
    "                                feat_drops=atom_param_dict[\"dropout\"])\n",
    "        \n",
    "        \n",
    "        # MaS_size is the size of the output of the last layer of the atom model\n",
    "        if model_type == \"GAT\":\n",
    "            if atom_param_dict[\"GAT_agg_modes\"][-1] == \"flatten\":\n",
    "                MaS_size = atom_param_dict[\"hidden_channels\"][-1]*atom_param_dict[\"heads\"][-1]\n",
    "            else:\n",
    "                MaS_size = atom_param_dict[\"hidden_channels\"][-1]\n",
    "            self.aggr = WeightedSumAndMax(MaS_size)\n",
    "        else:\n",
    "            self.aggr = WeightedSumAndMax(atom_param_dict[\"hidden_channels\"][-1])\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(concat_size, MLPsize)\n",
    "        self.linear2 = torch.nn.Linear(MLPsize, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None, batch_graph=None):\n",
    "        node_feats = batch_graph.ndata[self.nfeat_name]\n",
    "    \n",
    "        x1 = self.atom_lvl_model(batch_graph, node_feats)\n",
    "        x1 = self.aggr(batch_graph, x1)\n",
    "    \n",
    "        if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "            if self.include_motif:\n",
    "                x2 = self.motif_model(x, edge_index, edge_weight)\n",
    "                x = torch.cat((x1, x2), dim=1)\n",
    "            else:\n",
    "                x = x1\n",
    "\n",
    "        elif model_type == \"GAT\":\n",
    "            if self.include_motif:\n",
    "                x2 = self.motif_model(x, edge_index)\n",
    "                x = torch.cat((x1, x2), dim=1)\n",
    "            else:\n",
    "                x = x1\n",
    "    \n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # function to create the hyperparameters for the model\n",
    "    def create_params():\n",
    "\n",
    "        # optimizer and sampler\n",
    "        if motif_used:\n",
    "            amount_neighbors = trial.suggest_categorical(\"amount_neighbors\", [5, 10, 50, 100, 200])\n",
    "        epochs = trial.suggest_int(\"epochs\", 10, 100)\n",
    "        lr = trial.suggest_float(\"lr\", 0.0001, 0.1)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512, 1024])\n",
    "\n",
    "\n",
    "        # last MLP\n",
    "        MLP_size = trial.suggest_categorical(f\"MLP_size\", [8, 16, 32, 64, 128, 256, 512])\n",
    "        \n",
    "\n",
    "        if model_type == \"GNN\":\n",
    "            gnn_norm_motif = [False]\n",
    "            gnn_norm_atom = [\"none\"]\n",
    "        elif model_type == \"GCN\":\n",
    "            gnn_norm_motif = [True]\n",
    "            gnn_norm_atom = [\"both\"]\n",
    "\n",
    "\n",
    "        if motif_used:\n",
    "\n",
    "            motif_n_layers = trial.suggest_int(\"motif_n_layers\", 1, 8)\n",
    "            motif_hidden_channels = []\n",
    "            for i in range(motif_n_layers):\n",
    "                motif_hidden_channels.append(trial.suggest_categorical(f\"motif_hidden_channels_{i+1}\", [8, 16, 32, 64, 128, 256, 512]))\n",
    "\n",
    "            motif_activation_function = \"relu\"\n",
    "            if motif_activation_function == \"relu\":\n",
    "                motif_activations = [F.relu] * motif_n_layers\n",
    "\n",
    "            if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "                motif_param_dict = {\n",
    "                        \"n_layers\": motif_n_layers,\n",
    "                        \"activation_function\": motif_activations,\n",
    "                        \"gnn_norm\": gnn_norm_motif*motif_n_layers,\n",
    "                        \"hidden_channels\": motif_hidden_channels,\n",
    "                        \"dropout\": [nn.Dropout(trial.suggest_float(\"motif_dropout\", 0.0, 0.5))] * motif_n_layers,\n",
    "                    }\n",
    "            elif model_type == \"GAT\":\n",
    "                motif_param_dict = {\n",
    "                    \"n_layers\": motif_n_layers,\n",
    "                    \"activation_function\": motif_activations,\n",
    "                    \"hidden_channels\": motif_hidden_channels,\n",
    "                    \"dropout\": [trial.suggest_float(\"motif_dropout\", 0.0, 0.5)] * motif_n_layers,\n",
    "                    \"residual\": [trial.suggest_categorical(\"motif_residual\", [True, False])] * motif_n_layers,\n",
    "                    \"heads\": [trial.suggest_int(\"motif_heads\", 1, 3)]*motif_n_layers,\n",
    "                    \"GAT_agg_modes\": [trial.suggest_categorical(\"motif_GAT_agg_modes\", [\"flatten\", 'mean'])]*motif_n_layers # flatten is concat for this model\n",
    "                }\n",
    "        else:\n",
    "            motif_param_dict = {}\n",
    "         \n",
    "        \n",
    "        #atom model params\n",
    "\n",
    "        atom_n_layers = trial.suggest_int(\"atom_n_layers\", 1, 8)\n",
    "        atom_hidden_channels = []\n",
    "        for i in range(atom_n_layers):\n",
    "            atom_hidden_channels.append(trial.suggest_categorical(f\"atom_hidden_channels_{i+1}\", [8, 16, 32, 64, 128, 256, 512]))\n",
    "\n",
    "        atom_activation_function = \"relu\"\n",
    "        if atom_activation_function == \"relu\":\n",
    "            atom_activations = [F.relu] * atom_n_layers\n",
    "        \n",
    "        if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "            atom_param_dict = {\n",
    "                    \"n_layers\": atom_n_layers,\n",
    "                    \"activation_function\": atom_activations,\n",
    "                    \"gnn_norm\": gnn_norm_atom*atom_n_layers,\n",
    "                    \"hidden_channels\": atom_hidden_channels,\n",
    "                    \"dropout\": [trial.suggest_float(\"atom_dropout\", 0.0, 0.5)] * atom_n_layers,\n",
    "                }\n",
    "        elif model_type == \"GAT\":\n",
    "            atom_param_dict = {\n",
    "                \"n_layers\": atom_n_layers,\n",
    "                \"activation_function\": atom_activations,\n",
    "                \"hidden_channels\": atom_hidden_channels,\n",
    "                \"dropout\": [trial.suggest_float(\"atom_dropout\", 0.0, 0.5)] * atom_n_layers,\n",
    "                \"residual\": [trial.suggest_categorical(\"atom_residual\", [True, False])] * atom_n_layers,\n",
    "                \"heads\": [trial.suggest_int(\"atom_heads\", 1, 3)]*atom_n_layers,\n",
    "                \"GAT_agg_modes\": [trial.suggest_categorical(\"atom_GAT_agg_modes\", [\"flatten\", 'mean'])]*atom_n_layers # flatten is concat for this model\n",
    "            }\n",
    "        \n",
    "        atom_out_channels = atom_hidden_channels[-1]\n",
    "        if motif_used:\n",
    "            motif_out_channels = motif_hidden_channels[-1]\n",
    "\n",
    "\n",
    "        #final MLP input size(concat size), depends on if motif is used and the model type\n",
    "        if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "            if motif_used:\n",
    "                concat_size = atom_out_channels*2 + motif_out_channels\n",
    "            else:\n",
    "                concat_size = atom_out_channels*2\n",
    "       \n",
    "        elif model_type == \"GAT\":\n",
    "            if motif_used: \n",
    "            \n",
    "                if atom_param_dict[\"GAT_agg_modes\"][0] == \"flatten\" and motif_param_dict[\"GAT_agg_modes\"][0] == 'mean':\n",
    "                    concat_size = atom_out_channels*2*atom_param_dict[\"heads\"][0] + motif_out_channels\n",
    "                elif atom_param_dict[\"GAT_agg_modes\"][0] == \"flatten\" and motif_param_dict[\"GAT_agg_modes\"][0] == \"flatten\":\n",
    "                    concat_size = atom_out_channels*2*atom_param_dict[\"heads\"][0] + motif_out_channels*motif_param_dict[\"heads\"][0]\n",
    "                elif atom_param_dict[\"GAT_agg_modes\"][0] == 'mean' and motif_param_dict[\"GAT_agg_modes\"][0] == 'mean':\n",
    "                    concat_size = atom_out_channels*2 + motif_out_channels\n",
    "                elif atom_param_dict[\"GAT_agg_modes\"][0] == 'mean' and motif_param_dict[\"GAT_agg_modes\"][0] == \"flatten\":\n",
    "                    concat_size = atom_out_channels*2 + motif_out_channels*motif_param_dict[\"heads\"][0] \n",
    "\n",
    "            else:\n",
    "                if atom_param_dict[\"GAT_agg_modes\"][0] == \"flatten\":\n",
    "                    concat_size = atom_out_channels*2*atom_param_dict[\"heads\"][0] \n",
    "                else:\n",
    "                    concat_size = atom_out_channels*2\n",
    "        \n",
    "        return motif_param_dict, atom_param_dict, concat_size, lr, weight_decay, epochs, batch_size, MLP_size, amount_neighbors\n",
    "    \n",
    "\n",
    "\n",
    "    # get the hyperparameters\n",
    "    motif_param_dict, atom_param_dict, concat_size, lr, decay, epochs, batch_size, MLP_size, amount_neighbors = create_params()\n",
    "\n",
    "\n",
    "    if motif_used:\n",
    "        max_range_for_neighbor_sampler = [-1] + motif_param_dict[\"n_layers\"]*[amount_neighbors]\n",
    "    else:\n",
    "        # if motif is not used, the motif graph is not used.\n",
    "        max_range_for_neighbor_sampler = [0]\n",
    "\n",
    "\n",
    "    # sampler\n",
    "    sampler1 = ImbalancedSampler(data, data.train_mask)\n",
    "\n",
    "    # neighbor loader for the training, validation and test data\n",
    "    train_loader = NeighborLoader(data =data, sampler=sampler1 ,batch_size=batch_size,num_neighbors=max_range_for_neighbor_sampler, input_nodes=data.train_mask,weight_attr=\"edge_weight\")\n",
    "    val_loader = NeighborLoader(data = data, batch_size=batch_size,num_neighbors=max_range_for_neighbor_sampler, input_nodes=data.val_mask,weight_attr=\"edge_weight\")\n",
    "    test_loader = NeighborLoader(data =data, batch_size=batch_size,num_neighbors=max_range_for_neighbor_sampler, input_nodes=data.test_mask,weight_attr=\"edge_weight\")\n",
    "\n",
    "\n",
    "    # create the model\n",
    "    model_combined = Combined_model(motif_param_dict,atom_param_dict, concat_size,MLP_size, include_motif=motif_used)\n",
    "\n",
    "\n",
    "    # set the optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model_combined.parameters(), lr=lr, weight_decay=decay)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "    \n",
    "    # all the lists to store the results        \n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    all_test_loss = []\n",
    "    epoch_train_predict_values = [] # all predictions for each epoch\n",
    "    epoch_train_targets_values = [] # all targets for each epoch\n",
    "    epoch_val_predict_values = [] # all predictions for each epoch\n",
    "    epoch_val_targets_values = [] # all targets for each epoch\n",
    "    epoch_test_predict_values = [] # all predictions for each epoch\n",
    "    epoch_test_targets_values = [] # all targets for each epoch\n",
    "    best_val_loss = (100000, 0)\n",
    "    val_callback_counter=0\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        # reset if epoch based values for each epoch\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        epoch_val_p_values = []\n",
    "        epoch_val_t_values = []\n",
    "        epoch_train_p_values = []\n",
    "        epoch_train_t_values = []\n",
    "        epoch_test_p_values = []\n",
    "        epoch_test_t_values = []\n",
    "\n",
    "        # iterate over the training data\n",
    "        for batch in iter(train_loader):\n",
    "            model_combined.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_atom = indexes_to_batch_dgl_graphs(batch.atom_graphs, batch)\n",
    "\n",
    "            if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "                out = model_combined(batch.x, batch.edge_index, batch.edge_weight, batch_atom)\n",
    "            elif model_type == \"GAT\":\n",
    "                # if model is GAT, the edge_weight is not used\n",
    "                out = model_combined(batch.x, batch.edge_index, batch_graph = batch_atom)\n",
    "\n",
    "            train_loss = criterion(out[batch.train_mask], batch.y[batch.train_mask].float())\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # append predictions and targets to lists\n",
    "            epoch_train_p_values.extend(out[batch.train_mask].tolist())\n",
    "            epoch_train_t_values.extend(batch.y[batch.train_mask].tolist())\n",
    "\n",
    "            epoch_train_loss += train_loss.item()\n",
    "    \n",
    "\n",
    "        model_combined.eval()\n",
    "        with torch.no_grad():\n",
    "            # iterate over the test data, if test is used\n",
    "            if test_used:\n",
    "                for test_batch in iter(test_loader):\n",
    "                    batch_graph_test = indexes_to_batch_dgl_graphs(test_batch.atom_graphs, test_batch)\n",
    "                    if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "                        test_out = model_combined(test_batch.x, test_batch.edge_index, test_batch.edge_weight, batch_graph_test)\n",
    "                    elif model_type == \"GAT\":\n",
    "                        test_out = model_combined(test_batch.x, test_batch.edge_index, batch_graph =batch_graph_test)\n",
    "                    test_loss = criterion(test_out[test_batch.test_mask], test_batch.y[test_batch.test_mask].float())\n",
    "\n",
    "                    # append predictions and targets to lists\n",
    "                    epoch_test_p_values.extend(test_out[test_batch.test_mask].tolist())\n",
    "                    epoch_test_t_values.extend(test_batch.y[test_batch.test_mask].tolist())\n",
    "                    epoch_test_loss += test_loss.item()\n",
    "                \n",
    "                \n",
    "            # iterate over the validation data\n",
    "            for val_batch in iter(val_loader):\n",
    "                batch_graph_val = indexes_to_batch_dgl_graphs(val_batch.atom_graphs, val_batch)\n",
    "\n",
    "                if model_type == \"GNN\" or model_type == \"GCN\":\n",
    "                    val_out = model_combined(val_batch.x, val_batch.edge_index, val_batch.edge_weight, batch_graph_val)\n",
    "                elif model_type == \"GAT\":\n",
    "                    val_out = model_combined(val_batch.x, val_batch.edge_index, batch_graph = batch_graph_val)\n",
    "                val_loss = criterion(val_out[val_batch.val_mask], val_batch.y[val_batch.val_mask].float())\n",
    "\n",
    "                # append predictions and targets to lists\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                epoch_val_p_values.extend(val_out[val_batch.val_mask].tolist())\n",
    "                epoch_val_t_values.extend(val_batch.y[val_batch.val_mask].tolist())\n",
    "            \n",
    "            # send feedback to optuna\n",
    "            trial.report(epoch_val_loss, epoch)\n",
    "            if trial.should_prune(): \n",
    "                # save the results if the trial is pruned\n",
    "                save_trial_results(\"Pruned\", folder_path, trial, best_val_loss, epoch_train_predict_values, epoch_train_targets_values, epoch_val_predict_values, epoch_val_targets_values, all_train_loss, all_val_loss, epochs)\n",
    "                raise optuna.TrialPruned()\n",
    "            \n",
    "            # update the best validation loss during training\n",
    "            if epoch_val_loss < best_val_loss[0]:\n",
    "                print(f\"New best val_loss: {epoch_val_loss}, epoch: {epoch}, old best val_loss: {best_val_loss[0]}, epoch: {best_val_loss[1]}\")\n",
    "                best_val_loss = (epoch_val_loss, epoch)\n",
    "                \n",
    "\n",
    "            \n",
    "        \n",
    "        # append the loss values to the lists for each epoch        \n",
    "        all_train_loss.append(epoch_train_loss)\n",
    "        all_val_loss.append(epoch_val_loss)\n",
    "        epoch_train_predict_values.append(epoch_train_p_values)\n",
    "        epoch_train_targets_values.append(epoch_train_t_values)\n",
    "        epoch_val_predict_values.append(epoch_val_p_values)\n",
    "        epoch_val_targets_values.append(epoch_val_t_values)\n",
    "        if test_used:\n",
    "            all_test_loss.append(epoch_test_loss)\n",
    "            epoch_test_predict_values.append(epoch_test_p_values)\n",
    "            epoch_test_targets_values.append(epoch_test_t_values)\n",
    "\n",
    "\n",
    "    save_trial_results(\"Finished\", folder_path, trial, best_val_loss, epoch_train_predict_values, epoch_train_targets_values, epoch_val_predict_values, epoch_val_targets_values, all_train_loss, all_val_loss, epochs, test_used=True, epoch_test_predict_values=epoch_test_predict_values, epoch_test_targets_values=epoch_test_targets_values, test_loss=all_test_loss)\n",
    "        \n",
    "    return best_val_loss[0]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the current time for naming the study\n",
    "now = datetime.datetime.now().strftime(\"%H-%M-%S_%d-%m-%Y\")\n",
    "\n",
    "# Creates a unique study name\n",
    "study_name = f\"study_{now}\"\n",
    "\n",
    "# Defines the folder path for saving study results\n",
    "folder_path = os.path.join(f\"{model_type}_motif={motif_used}\", study_name)\n",
    "os.makedirs(folder_path, exist_ok=True)  \n",
    "\n",
    "\n",
    "# Define the study (optuna object)\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///db.sqlite3\",  # Specify the database storage URL\n",
    "    study_name=study_name,\n",
    "    direction=\"minimize\",\n",
    "    pruner=optuna.pruners.PercentilePruner(\n",
    "        percentile=25.0,  # Prune the bottom 75% of trials\n",
    "        n_startup_trials=30,  # Start pruning after 30 trials\n",
    "        n_warmup_steps=10,    # Allow 10 warmup epochs before pruning\n",
    "        interval_steps=10     # Check pruning every 10 epochs\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective, n_trials=500, show_progress_bar=True)\n",
    "\n",
    "# Print the best trial results\n",
    "print(f\"Best value: {study.best_value} (params: {study.best_params})\")\n",
    "\n",
    "# Save the study trials to a CSV file\n",
    "output_csv_path = os.path.join(folder_path, f\"trials_{study_name}_{model_type}_{motif_used}.csv\")\n",
    "study.trials_dataframe().to_csv(output_csv_path)\n",
    "print(f\"Study results saved to: {output_csv_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
